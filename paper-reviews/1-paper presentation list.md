## Paper presentation list



We plan to present one paper for each group disccusion. Please add the presentation in the format of ``time, paper title（conference、journal), name''.

1) 9.17, iGniter: Interference-Aware GPU Resource Provisioning for Predictable DNN Inference in the Cloud（TPDS'24）, Fei Xu
2) 9.24, Optimizing Resource Allocation in Hyperscale Datacenters: Scalability, Usability, and Experiences（OSDI'24）, Zongqing Wei
3) 10.15, Metis: Fast Automatic Distributed Training on Heterogeneous GPUs （ATC’24）, Ruixing Li
4) 10.22, dLoRA: Dynamically Orchestrating Requests and Adapters for LoRA LLM Serving （OSDI'24), Lingxuan Weng
5) 10.29, StreamBox: A Lightweight GPU SandBox for Serverless Inference Workflow (ATC'24), Yikun Gu
6) 10.29, DynaPipe: Optimizing Multi-task Training through Dynamic Pipelines (Eurosys'24), Qiannan Zhou
7) 11.6, ModelKeeper: Accelerating DNN Training via Automated Training Warmup (NSDI'23), XiangShen
8) 11.6, Starburst: A Cost-aware Scheduler for Hybrid Cloud(ATC'24), Zongqing Wei
9) 11.12, Pre-Warming is Not Enough: Accelerating Serverless Inference With Opportunistic Pre-Loading (SOCC'24), Yikun Gu
10) 11.12, mLoRA: Fine-Tuning LoRA Adapters via Highly-Efficient Pipeline Parallelism in Multiple GPUs (under revision in VLDB’25), Lingxuan Weng
11) 11.19, USHER：Holistic Interference Avoidance for Resource Optimized ML Inference (OSDI'24), Xiang Shen
12) 11.19, Managing Bandwidth: The Key to Cloud-Assisted Autonomous Driving (arXiv'24), Zongqing Wei
13) 11.26, SMIless: Serving DAG-based Inference with Dynamic Invocations under Serverless Computing (SC'24), Yikun Gu
14) 11.26, Online Scheduling and Pricing for Multi-LoRA Fine-Tuning Tasks(ICPP'24), Lingxuan Weng
15) 12.3, AutoBurst: Autoscaling Burstable Instances for Cost-effective Latency SLOs(SOCC'24), Zongqing wei
16) 12.3, Optimus: Warming Serverless ML Inference via Inter-Function Model Transformation(Eurosys'24), Xiang Shen
17) 12.10, Jolteon: Unleashing the Promise of Serverless for Serverless Workflows(NSDI'24), Yikun Gu
18) 12.10, Kale: Elastic GPU Scheduling for Online DL Model Training(SOCC'24), Lingxuan Weng
19) 12.17, Delta: A Cloud-assisted Data Enrichment Framework for On-Device Continual Learning(MobiCom'24), Zongqing Wei
20) 12.17, Near-Lossless Gradient Compression for Data-Parallel Distributed DNN Training(SOCC'24), Xiang Shen
21) 12.24, DistServe: Disaggregating Prefill and Decoding for Goodput-optimized  Large Language Model Serving(OSDI'24), Lingxuan Weng
22) 12.24, PISeL Pipelining DNN Inference for Serverless Computing(CIKM'24), Yikun Gu
23) 12.31, FlexNN: Efficient and Adaptive DNN Inference on Memory-Constrained Edge Devices(MobiCom'24), Zongqing Wei
24) 1.7, PowerInfer Fast Large Language Model Serving with a Consumer-grade GPUTraining(SOSP'24), Xiang Shen


